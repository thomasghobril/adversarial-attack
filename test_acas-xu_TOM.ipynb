{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.losses import categorical_crossentropy as CCE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load properties from another python file\n",
    "from properties import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"ACAS_XU_tf_keras/ACASXU_1_1.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_11 = load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_35 = load_model(\"ACAS_XU_tf_keras/ACASXU_3_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_98 (Dense)            (None, 50)                300       \n",
      "                                                                 \n",
      " activation_98 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dense_99 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " activation_99 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dense_100 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " activation_100 (Activation)  (None, 50)               0         \n",
      "                                                                 \n",
      " dense_101 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " activation_101 (Activation)  (None, 50)               0         \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " activation_102 (Activation)  (None, 50)               0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " activation_103 (Activation)  (None, 50)               0         \n",
      "                                                                 \n",
      " dense_104 (Dense)           (None, 5)                 255       \n",
      "                                                                 \n",
      " activation_104 (Activation)  (None, 5)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,305\n",
      "Trainable params: 13,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_35.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.array([1.0, 1.0, 1.0, 1.0, 1.0]).reshape(1,5)\n",
    "model_11.predict(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.array([1.0, 1.0, 1.0, 1.0, 1.0]).reshape(1,5)\n",
    "model_35.predict(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adv_sample(model, x0, label, loss_function=\"MSE\", eps=1e-5):\n",
    "    # transforming into a tensorflow object\n",
    "    x0_ = tf.cast(x0, tf.float32)\n",
    "    \n",
    "    # record our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # explicitly indicate that our input should be tacked for gradient updates\n",
    "        tape.watch(x0_)\n",
    "\n",
    "        # use our model to make predictions on the input and then compute the loss\n",
    "        pred = model(x0_)\n",
    "        if loss_function == \"CCE\":\n",
    "            np_label = np.array([i==label for i in range(0,5)]).reshape((1,5))\n",
    "            loss = CCE(np_label, pred)\n",
    "        elif loss_function == \"MSE\":\n",
    "            loss = MSE(label, pred)\n",
    "        else:\n",
    "            raise Exception(\"Unknown loss function '{0}'\".format(loss_function))\n",
    "        \n",
    "        # calculate the gradients of loss with respect to the input, then compute the sign of the gradient\n",
    "        gradient = tape.gradient(loss, x0_)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "\n",
    "        # construct the image adversary\n",
    "        adv_sample = (x0_ + (signedGrad * eps)).numpy()\n",
    "\n",
    "        # return the adversarial sample to the calling function\n",
    "        return(adv_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_adv = generate_adv_sample(model_11, pt, label = 0, loss_function = \"CCE\", eps=1e-3)\n",
    "print(x0_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.predict(x0_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_label = np.array([int(i==2) for i in range(0,5)]).reshape((1,5))\n",
    "np_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pts(n, prop_dom, main_dom):\n",
    "    \"\"\" prop_dom is a list of domains given by intervals in a numpy 2x5 table. \"\"\"\n",
    "    ndom = len(prop_dom)\n",
    "    ndim = main_dom.shape[1]\n",
    "    \n",
    "    x = np.zeros((n,ndim))\n",
    "    for i in range(n): # generate the i-th point\n",
    "        choosen_dom = prop_dom[randint(0,ndom-1)] # choose the input property domain for a given prop\n",
    "        for k in range(ndim): # create a random coord for each dim\n",
    "            boundaries = main_dom[:,k]\n",
    "            if choosen_dom[0,k] != None:\n",
    "                boundaries[0] = choosen_dom[0,k]\n",
    "            if choosen_dom[1,k] != None:\n",
    "                boundaries[1] = choosen_dom[1,k]\n",
    "            x[i,k] = boundaries[0] + random()*(boundaries[1]-boundaries[0])\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, x_mean, x_range):\n",
    "    (n,k) = x.shape\n",
    "    nx = np.zeros((n,k))\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            nx[i,j] = (x[i,j]-x_mean[j])/x_range[j]\n",
    "    return(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pts(model, input_pts, IP, OP):\n",
    "    n = input_pts.shape[0]\n",
    "    IO_check = np.zeros((n,2)) # 1st column : input checked - 2nd column : output checked\n",
    "    \n",
    "    norm_input = normalize(input_pts, X_mean, X_range) # normalize pts\n",
    "    \n",
    "    pred_pts = model.predict(norm_input) # make predictions with the model (neural net)\n",
    "    \n",
    "    for k in range(n):\n",
    "        IO_check[k,0] = IP(input_pts[k,:]) # check input (just in case)\n",
    "        IO_check[k,1] = OP(pred_pts[k,:]) # check output\n",
    "\n",
    "    return(IO_check, pred_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.65399259e+04 -1.06280337e+00  6.93948977e-01  1.14894048e+03\n",
      "   5.46869882e+01]\n",
      " [ 5.62140790e+04  1.82724881e+00  2.81804609e+00  1.18205705e+03\n",
      "   9.19801608e-01]\n",
      " [ 5.83717144e+04  1.28881663e+00  5.32541245e-01  1.19100463e+03\n",
      "   4.37645376e+01]\n",
      " [ 5.88605325e+04 -2.55605764e-01 -2.53960890e+00  1.19430519e+03\n",
      "   5.80021110e+00]\n",
      " [ 5.72159842e+04 -5.61606981e-01 -1.59989365e+00  1.15520853e+03\n",
      "   2.95549577e+01]\n",
      " [ 5.85248429e+04  2.03645450e+00 -1.58755871e+00  1.18583048e+03\n",
      "   5.86414730e+01]\n",
      " [ 5.63006282e+04 -8.60885938e-01  1.45061203e+00  1.19775165e+03\n",
      "   1.98538536e+01]\n",
      " [ 5.88870929e+04  2.13785846e+00 -1.34665514e+00  1.17127115e+03\n",
      "   3.36253026e+01]\n",
      " [ 5.63375468e+04 -2.39428233e+00  2.42154936e-01  1.15041568e+03\n",
      "   1.00649320e+01]\n",
      " [ 5.90527600e+04 -1.34307909e+00 -2.07606938e+00  1.19029353e+03\n",
      "   2.10400198e+01]]\n"
     ]
    }
   ],
   "source": [
    "rand_inputs = random_pts(10, IP2_dom, X_dom)\n",
    "print(rand_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pcheck, pred_pts = check_pts(model_11, rand_inputs, IP1, OP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adverse(input_pts, prop_check):\n",
    "    n = prop_check.shape[0]\n",
    "    index = []\n",
    "    for k in range(n):\n",
    "        if prop_check[k,0] and not(prop_check[k,1]):\n",
    "            index.append(k)\n",
    "    return(input_pts[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5)\n"
     ]
    }
   ],
   "source": [
    "adv = find_adverse(rand_inputs, Pcheck)\n",
    "print(adv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pcheck.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the target tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22136/796836400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mrand_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_pts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIP1_dom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_dom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[0mrand_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrand_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstats_fgsm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrand_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22136/796836400.py\u001b[0m in \u001b[0;36mstats_fgsm\u001b[1;34m(model, dataset, var)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0msame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margmin_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0margmin_adversary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfgsm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margmin_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margmin_adversary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22136/796836400.py\u001b[0m in \u001b[0;36mfgsm\u001b[1;34m(x, model, var, label)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# calculate the gradients of loss with respect to the image, then compute the sign of the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0msignedGrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# construct the image adversary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
     ]
    }
   ],
   "source": [
    "def bool_to_binary(b):\n",
    "    if b:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def fgsm(x,model,var,label):\n",
    "\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    eps=[(X_dom[1][i]-X_dom[0][i])*var for i in range(5)]\n",
    "    # record our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # explicitly indicate that our image should be tacked for gradient updates\n",
    "        tape.watch(x)\n",
    "\n",
    "        # use our model to make predictions on the input image and then compute the loss\n",
    "        #label = model.predict(x)\n",
    "        loss = MSE(label, [0,0,0,0,0])\n",
    "        \n",
    "        # calculate the gradients of loss with respect to the image, then compute the sign of the gradient\n",
    "        gradient = tape.gradient(loss, x)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "\n",
    "        # construct the image adversary\n",
    "        adversary = (x + (signedGrad * eps))\n",
    "        adversary_img=model.predict(adversary)\n",
    "        \n",
    "        argmin_label= np.argmin(label)\n",
    "        argmin_adversary=np.argmin(adversary_img)\n",
    "\n",
    "        same= (argmin_label==argmin_adversary)\n",
    "        same=bool_to_binary(same)\n",
    "\n",
    "        return(same,argmin_label,argmin_adversary)\n",
    "\n",
    "def stats_fgsm(model,dataset,var):\n",
    "    label=model.predict(dataset)\n",
    "    res=np.zeros((5,5))\n",
    "    for i in range(len(dataset)):\n",
    "        same,argmin_label,argmin_adversary=fgsm(dataset[i],model,var,label[i])\n",
    "        res[argmin_label][argmin_adversary]+=1\n",
    "    return res\n",
    "\n",
    "rand_inputs = random_pts(10000, IP1_dom, X_dom)\n",
    "rand_inputs = normalize(rand_inputs, X_mean, X_range)\n",
    "stats=stats_fgsm(model_11, rand_inputs,0.01)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
