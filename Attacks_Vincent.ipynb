{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import pi\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.losses import categorical_crossentropy as CCE\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import *\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load properties from another python file\n",
    "from properties import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"ACAS_XU_tf_keras/ACASXU_1_1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11 = load_model(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_35 = load_model(\"ACAS_XU_tf_keras/ACASXU_3_5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_35.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.array([1.0, 1.0, 1.0, 1.0, 1.0]).reshape(1,5)\n",
    "model_11.predict(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.array([1.0, 1.0, 1.0, 1.0, 1.0]).reshape(1,5)\n",
    "model_35.predict(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACAS_model = model_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Carlini & Wagner = CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adv_sample(model, x0, label, loss_function=\"MSE\", eps=1e-5):\n",
    "    # transforming into a tensorflow object\n",
    "    x0_ = tf.cast(x0, tf.float32)\n",
    "    \n",
    "    # record our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # explicitly indicate that our input should be tacked for gradient updates\n",
    "        tape.watch(x0_)\n",
    "\n",
    "        # use our model to make predictions on the input and then compute the loss\n",
    "        pred = model(x0_)\n",
    "        if loss_function == \"CCE\":\n",
    "            np_label = np.array([i==label for i in range(0,5)]).reshape((1,5))\n",
    "            loss = CCE(np_label, pred)\n",
    "        elif loss_function == \"MSE\":\n",
    "            loss = MSE(label, pred)\n",
    "        else:\n",
    "            raise Exception(\"Unknown loss function '{0}'\".format(loss_function))\n",
    "        \n",
    "        # calculate the gradients of loss with respect to the input, then compute the sign of the gradient\n",
    "        gradient = tape.gradient(loss, x0_)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "\n",
    "        # construct the image adversary\n",
    "        adv_sample = (x0_ + (signedGrad * eps)).numpy()\n",
    "\n",
    "        # return the adversarial sample to the calling function\n",
    "        return(adv_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Generate points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pts(n, prop_dom, main_dom):\n",
    "    \"\"\" prop_dom is a list of domains given by intervals in a numpy 2x5 table. \"\"\"\n",
    "    ndom = len(prop_dom)\n",
    "    ndim = main_dom.shape[1]\n",
    "    \n",
    "    x = np.zeros((n,ndim))\n",
    "    for i in range(n): # generate the i-th point\n",
    "        choosen_dom = prop_dom[randint(0,ndom-1)] # choose the input property domain for a given prop\n",
    "        for k in range(ndim): # create a random coord for each dim\n",
    "            boundaries = main_dom[:,k]\n",
    "            if choosen_dom[0,k] != None:\n",
    "                boundaries[0] = choosen_dom[0,k]\n",
    "            if choosen_dom[1,k] != None:\n",
    "                boundaries[1] = choosen_dom[1,k]\n",
    "            x[i,k] = boundaries[0] + random()*(boundaries[1]-boundaries[0])\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_main_pts(n, main_dom):\n",
    "    \"\"\" Generate random points in the main domain given by intervals stored in a numpy 2x5 table. \"\"\"\n",
    "    ndim = main_dom.shape[1]\n",
    "    \n",
    "    x = np.zeros((n,ndim))\n",
    "    for k in range(ndim): # create a random coord for each dim\n",
    "        col = main_dom[0,k]*np.ones((n,1)) + np.random.rand(n,1)*(main_dom[1,k] - main_dom[0,k])\n",
    "        for i in range(n):\n",
    "            x[i,k] = col[i]\n",
    "\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = random_main_pts(1000, X_dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, x_mean, x_range):\n",
    "    (n,k) = x.shape\n",
    "    nx = np.zeros((n,k))\n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            nx[i,j] = (x[i,j]-x_mean[j])/x_range[j]\n",
    "    return(nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pts(model, input_pts, IP, OP):\n",
    "    n = input_pts.shape[0]\n",
    "    IO_check = np.zeros((n,2)) # 1st column : input checked - 2nd column : output checked\n",
    "    \n",
    "    norm_input = normalize(input_pts, X_mean, X_range) # normalize pts\n",
    "    \n",
    "    pred_pts = model.predict(norm_input) # make predictions with the model (neural net)\n",
    "    \n",
    "    for k in range(n):\n",
    "        IO_check[k,0] = IP(input_pts[k,:]) # check input (just in case)\n",
    "        IO_check[k,1] = OP(pred_pts[k,:]) # check output\n",
    "\n",
    "    return(IO_check, pred_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_inputs = random_pts(1000000, IP2_dom, X_dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pcheck, pred_pts = check_pts(model_11, rand_inputs, IP1, OP1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_adverse(input_pts, prop_check):\n",
    "    n = prop_check.shape[0]\n",
    "    index = []\n",
    "    for k in range(n):\n",
    "        if prop_check[k,0] and not(prop_check[k,1]):\n",
    "            index.append(k)\n",
    "    return(input_pts[index,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = find_adverse(rand_inputs, Pcheck)\n",
    "print(adv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pcheck.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Attack the networks : FGSM & CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACAS_model = load_model(\"ACAS_XU_tf_keras/ACASXU_1_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier object <~> neural network ACAS-Xu ...\n",
    "\n",
    "ACAS_classifier = TensorFlowV2Classifier(model = ACAS_model,\n",
    "                                         loss_object = MSE, # MSE or CCE ?...\n",
    "                                         train_step = None,\n",
    "                                         nb_classes = 5,\n",
    "                                         input_shape = (1, 5, 1),\n",
    "                                         clip_values = (-1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test = 0.8*np.array([ [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "#                         [0.6, 0.5, 1.0, 0.3, 1.0] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carlini-Wagner (CW) attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_CW = CarliniLInfMethod(classifier=ACAS_classifier,\n",
    "                              initial_const = 1.0, \n",
    "                              max_iter = 100, \n",
    "                              # targeted=True, \n",
    "                              verbose = True)\n",
    "\n",
    "# x_adv_cw = attack_CW.generate(x_test) #, y=np.array([[0,1,0,0,0]]))\n",
    "# print(x_adv_cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast Gradient Sign Method (FGSM) attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_fgsm = 0.8\n",
    "\n",
    "attack_FGSM = FastGradientMethod(estimator = ACAS_classifier,\n",
    "                                 eps = intensity_fgsm,\n",
    "                                 verbose = True)\n",
    "\n",
    "# x_adv_fgsm = attack_FGSM.generate(x_test)\n",
    "# print(x_adv_fgsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create random (normalized) points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_pts = np.random.rand(1000, 5) # random_main_pts(10, X_dom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CW\n",
    "adv_pts_cw = attack_CW.generate(original_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM\n",
    "adv_pts_fgsm = attack_FGSM.generate(original_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CW adv points\")\n",
    "print(adv_pts_cw,\"\\n\")\n",
    "\n",
    "print(\"FGSM adv points\")\n",
    "print(adv_pts_fgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the adversarial points\n",
    "\n",
    "original_pred = ACAS_model.predict(original_pts)\n",
    "adv_pred_cw = ACAS_model.predict(adv_pts_cw)\n",
    "adv_pred_fgsm = ACAS_model.predict(adv_pts_fgsm)\n",
    "\n",
    "print(\"Original pred :\")\n",
    "print(original_pred,\"\\n\")\n",
    "\n",
    "print(\"CW pred :\")\n",
    "print(adv_pred_cw,\"\\n\")\n",
    "\n",
    "print(\"FGSM pred :\")\n",
    "print(adv_pred_fgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get advices from the predictions of the network (prediction = min score)\n",
    "\n",
    "original_advice = np.argmin(original_pred, axis=1)\n",
    "cw_advice = np.argmin(adv_pred_cw, axis=1)\n",
    "fgsm_advice = np.argmin(adv_pred_fgsm, axis=1)\n",
    "\n",
    "print(original_advice[:20])\n",
    "print(cw_advice[:20])\n",
    "print(fgsm_advice[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results visualization with confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(pred0, pred1, n_classes=5):\n",
    "    \"\"\" Create the n_classes*n_classes confusion matrix of pred1 compared to the original pred0. \n",
    "        - cmat[i,j] = nb of pts classified as i at the origin and as j after the attack \"\"\"\n",
    "    cmat = np.zeros((n_classes,n_classes)).astype(int)\n",
    "    n_sample = pred0.shape[0]\n",
    "    for k in range(n_sample):\n",
    "        cmat[pred0[k],pred1[k]] += 1\n",
    "    return(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_rows(cmat):\n",
    "    \"\"\" Normalize the lines of the confusion matrix cmat. \"\"\"\n",
    "    n = cmat.shape[0]\n",
    "    ncmat = np.zeros((n,n))\n",
    "    sum_rows = np.sum(cmat_cw, axis=1)\n",
    "    for k in range(n):\n",
    "        s = sum_rows[k]\n",
    "        if s != 0:\n",
    "            ncmat[k,:] = cmat[k,:]/sum_rows[k]\n",
    "    return(ncmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cmat_cw = confusion_matrix(original_advice, cw_advice)\n",
    "print(cmat_cw)\n",
    "\n",
    "# confusion matrix with normalized lines\n",
    "ncmat_cw = norm_rows(cmat_cw)\n",
    "print(ncmat_cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cmat_fgsm = confusion_matrix(original_advice, fgsm_advice)\n",
    "print(cmat_fgsm)\n",
    "\n",
    "# confusion matrix with normalized lines\n",
    "ncmat_fgsm = norm_rows(cmat_fgsm)\n",
    "print(ncmat_fgsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix plot legend\n",
    "index0 = [\"COC\",\"WR\",\"WL\",\"SR\",\"SL\"]\n",
    "index1 = [\"adv-COC\",\"adv-WR\",\"adv-WL\",\"adv-SR\",\"adv-SL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix for CW attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmat = pd.DataFrame(ncmat_cw, index = index0, columns = index1)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cmat, annot=True)\n",
    "plt.title(\"Confusion matrix - CW - #{0}\".format(1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot confusion matrix for FGSM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cmat = pd.DataFrame(ncmat_fgsm, index = index0, columns = index1)\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cmat, annot=True)\n",
    "plt.title(\"Confusion matrix - FGSM - #{0}\".format(1000))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
