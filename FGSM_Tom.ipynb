{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class SimpleCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model along with the input shape\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "\n",
    "        # first CONV => RELU => BN layer set\n",
    "        model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "        # second CONV => RELU => BN layer set\n",
    "        model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return(model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-ee3e7a1c18db>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-ee3e7a1c18db>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    inp = tf.keras.Input(shape=(28,28,1))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# The model that you will implement should have the following architecture\n",
    "#1 -> Convolutional layer with 6 kernels and tanh activation function\n",
    "#2 -> Max pooling downsampling the image by 2\n",
    "#3 -> Convolutional layer with 16 kernels and tanh activation function\n",
    "#4 -> Max pooling downsampling the image by 2\n",
    "#5 -> Fully connected layer with 120 units\n",
    "#6 -> Fully connected layer with 84 units\n",
    "#7 -> Fully connected layer with 10 units\n",
    "\n",
    "class SimpleCNN:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "    # Demo Model Definition\n",
    "    inp = tf.keras.Input(shape=(28,28,1))\n",
    "\n",
    "    l1 = tf.keras.layers.Conv2D(filters=6, kernel_size=3, activation='tanh')(inp)\n",
    "    l2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(l1)\n",
    "    l3 = tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='tanh')(l2)\n",
    "    # Each kernel is a 3*3 matrix = (kernel_size*kernel_size matrix). However, there as 6 channels as inputs.\n",
    "    # Therefore, each filter is in reality composed of 6 kernels and thus is a 6*3*3 matrix. \n",
    "    # Hence we get 6*3*3+1 (+1=bias) = 55 coeff per filter.\n",
    "    # As we have 16 filters, we get 16*55=880 coeff.\n",
    "\n",
    "    l4 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(l3)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(l4)\n",
    "    # We flatten a 5*5*16 D object, we get a 400D vector.\n",
    "\n",
    "    l5 = tf.keras.layers.Dense(120, activation='tanh')(x)\n",
    "    # Dense from 400D to 120D + 120 bias = 401*120 = 48120 coeff.\n",
    "    l6 = tf.keras.layers.Dense(84, activation='tanh')(l5)\n",
    "    out = tf.keras.layers.Dense(10, activation='softmax')(l6)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inp, outputs=out)\n",
    "    model.summary()\n",
    "    return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy as CCE\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_adversary(model, image, label, eps=2 / 255.0):\n",
    "    # cast the image\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    # record our gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        # explicitly indicate that our image should be tacked for gradient updates\n",
    "        tape.watch(image)\n",
    "\n",
    "        # use our model to make predictions on the input image and then compute the loss\n",
    "        pred = model(image)\n",
    "        loss = CCE(label, pred)\n",
    "        \n",
    "        # calculate the gradients of loss with respect to the image, then compute the sign of the gradient\n",
    "        gradient = tape.gradient(loss, image)\n",
    "        signedGrad = tf.sign(gradient)\n",
    "\n",
    "        # construct the image adversary\n",
    "        adversary = (image + (signedGrad * eps)).numpy()\n",
    "\n",
    "        # return the image adversary to the calling function\n",
    "        return(adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "# load MNIST dataset and scale the pixel values to the range [0, 1]\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0\n",
    "\n",
    "# add a channel dimension to the images\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "\n",
    "# one-hot encode our labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=1e-3)\n",
    "model = SimpleCNN.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the simple CNN on MNIST\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=64, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions on the testing set for the model trained on\n",
    "# non-adversarial images\n",
    "(loss, acc) = model.evaluate(x=testX, y=testY, verbose=0)\n",
    "print(\"[INFO] loss: {:.4f}, acc: {:.4f}\".format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_12_02_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: model_12_02_2022/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-157da9d1232d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_12_02_2022\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0mloader_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    109\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot parse file %s: %s.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpath_to_pbtxt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m     raise IOError(\"SavedModel file does not exist at: %s/{%s|%s}\" %\n\u001b[0m\u001b[0;32m    112\u001b[0m                   (export_dir,\n\u001b[0;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: model_12_02_2022/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = load_model(\"model_12_02_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_adv = 4\n",
    "\n",
    "# f, axarr = plt.subplots(n_adv, figsize=(50, 50))\n",
    "fig, axs = plt.subplots(n_adv, 2, figsize=(500,500), constrained_layout=True)\n",
    "\n",
    "# loop over a sample of our testing images\n",
    "num = 0\n",
    "for i in np.random.choice(np.arange(0, len(testX)), size=(n_adv,)):\n",
    "    # grab the current image and label\n",
    "    image = testX[i] ; label = testY[i]\n",
    "    pred = model.predict(image.reshape((1,28,28,1)))\n",
    "\n",
    "    # generate an image adversary for the current image and make\n",
    "    # a prediction on the adversary\n",
    "    adversary = generate_image_adversary(model, image.reshape(1, 28, 28, 1), label, eps=0.1)\n",
    "    adv_pred = model.predict(adversary)\n",
    "    adv_image = adversary.reshape((28,28))\n",
    "    \n",
    "    axs[num,0].imshow(image.reshape((28,28)), cmap='gray')\n",
    "    axs[num,0].get_xaxis().set_visible(False) ; axs[num,0].get_yaxis().set_visible(False)\n",
    "    axs[num,0].set_title(\"IMG : {:.0f} | PRED : {:.0f} ({:.2f}%)\".format(i,np.argmax(pred),np.max(pred)*100))\n",
    "    \n",
    "    axs[num,1].imshow(adv_image, cmap='gray')\n",
    "    axs[num,1].get_xaxis().set_visible(False) ; axs[num,1].get_yaxis().set_visible(False)\n",
    "    axs[num,1].set_title(\"ADV_IMG : {:.0f} | PRED : {:.0f} ({:.2f}%)\".format(i,np.argmax(adv_pred),np.max(adv_pred)*100))\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
